{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix in Plotly\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def make_correlation_matrix(df = df_churn):   \n",
    "    '''\n",
    "    produces a plotly correlation matrix\n",
    "    \n",
    "    INPUT: dataframe\n",
    "    \n",
    "\tNOTE: you need to store the output of this function in a cariable, \n",
    "\tand then put that in a new line to see the plot.\n",
    "\tlike so:\n",
    "\n",
    "\tout = make_correlation_matrix(df_churn_scaled)\n",
    "\tout\n",
    "\t\n",
    "    '''\n",
    "    correlations = df.corr()\n",
    "    matrix_columns = correlations.columns.tolist()\n",
    "    corr_array  = np.array(correlations)\n",
    "\n",
    "    \n",
    "    heat = go.Heatmap(z = corr_array,\n",
    "                        x = matrix_columns,\n",
    "                        y = matrix_columns,\n",
    "                        colorscale = \"Jet\",\n",
    "                        colorbar   = dict(title = \"Pearson correlation coefficient\",\n",
    "                                         titleside = \"right\"\n",
    "                                        ) ,\n",
    "                      )\n",
    "\n",
    "    layout = go.Layout(dict(title = \"Correlation Matrix\",\n",
    "                            \n",
    "                            height  = 600,\n",
    "                            width   = 800,\n",
    "                            margin  = dict(r = 0 ,l = 200,\n",
    "                                           t = 25,b = 200,\n",
    "                                          ),\n",
    "                            yaxis   = dict(tickfont = dict(size = 10)),\n",
    "                            xaxis   = dict(tickfont = dict(size = 10))\n",
    "                           )\n",
    "                      )\n",
    "\n",
    "    fig = go.Figure(data= [heat],layout=layout)\n",
    "    return py.iplot(fig, filename = 'correlation-matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing threshold\n",
    "probabilities = rfc_smote.predict_proba(X_test_st)[:,1]\n",
    "reals = y_test\n",
    "best_cost = -10**10\n",
    "best_thresh = 0\n",
    "\n",
    "for threshold in np.linspace(0,1,101):\n",
    "    predictions = probabilities >= threshold\n",
    "    tp = sum((reals == 1) & (predictions == 1))\n",
    "    fp = sum((reals == 0) & (predictions == 1))\n",
    "    tn = sum((reals == 0) & (predictions == 0))\n",
    "    fn = sum((reals == 1) & (predictions == 0))\n",
    "    tp_c = 2\n",
    "    fp_c = -6\n",
    "    tn_c = 0\n",
    "    fn_c = -1\n",
    "    cost = tp*tp_c + fp*fp_c + tn*tn_c + fn*fn_c\n",
    "    if cost > best_cost:\n",
    "        best_cost = cost\n",
    "        best_thresh = threshold\n",
    "    #print(f'cost is {cost} and threshold is {threshold}')\n",
    "    #print(f'tp is {tp}, fp is {fp}, tn is {tn}, fn is {fn}')\n",
    "        \n",
    "print(f'Optimal threshold is: {best_thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (knn)\n",
    "\n",
    "ks = [501]\n",
    "param_grid = [{'n_neighbors': ks}]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc', verbose=30, n_jobs=-1)\n",
    "knn_grid.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R formula function\n",
    "\n",
    "\n",
    "def ols_formula(df, dependent_var, *excluded_cols):\n",
    "    '''\n",
    "    Generates the R style formula for statsmodels (patsy) given\n",
    "    the dataframe, dependent variable and optional excluded columns\n",
    "    as strings\n",
    "    '''\n",
    "    df_columns = list(df.columns.values)\n",
    "    df_columns.remove(dependent_var)\n",
    "    for col in excluded_cols:\n",
    "        df_columns.remove(col)\n",
    "    return dependent_var + ' ~ ' + ' + '.join(df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To keep validation set apart from the test set in order to oversample/undersample your test set during cross validation perform the following:\n",
    "random_seed = 123\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_seed)\n",
    "cross_val_f1_score_lst = []\n",
    "cross_val_accuracy_lst = []\n",
    "cross_val_recall_lst = []\n",
    "cross_val_precision_lst = []\n",
    "\n",
    "for train_index_ls, validation_index_ls in kf.split(x_train, y_train):\n",
    "    # keeping validation set apart and oversampling in each iteration using smote \n",
    "    train, validation = x_train.iloc[train_index_ls], x_train.iloc[validation_index_ls]\n",
    "    target_train, target_val = y_train.iloc[train_index_ls], y_train.iloc[validation_index_ls]\n",
    "    sm = SMOTE(random_state=random_seed)\n",
    "    X_train_res, y_train_res = sm.fit_sample(train, target_train)\n",
    "    print (X_train_res.shape, y_train_res.shape)\n",
    "    \n",
    "    # training the model on oversampled 4 folds of training set\n",
    "    rf = RandomForestClassifier(n_estimators=5, random_state=random_seed)\n",
    "    rf.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    # testing on 1 fold of validation set\n",
    "    validation_preds = rf.predict(validation)\n",
    "    cross_val_recall_lst.append(recall_score(target_val, validation_preds))\n",
    "    cross_val_accuracy_lst.append(accuracy_score(target_val, validation_preds))\n",
    "    cross_val_precision_lst.append(precision_score(target_val, validation_preds))\n",
    "    cross_val_f1_score_lst.append(f1_score(target_val, validation_preds))\n",
    "    \n",
    "print ('Cross validated accuracy: {}'.format(np.mean(cross_val_accuracy_lst)))\n",
    "print ('Cross validated recall score: {}'.format(np.mean(cross_val_recall_lst)))\n",
    "print ('Cross validated precision score: {}'.format(np.mean(cross_val_precision_lst)))\n",
    "print ('Cross validated f1_score: {}'.format(np.mean(cross_val_f1_score_lst)))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "///\n",
    "X_cat_train = X_train.select_dtypes(include='object')\n",
    "X_cat_train = pd.DataFrame(X_cat_train,dtype ='str')\n",
    "imp_freq_train = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_cat_imputed_train = imp_freq_train.fit_transform(X_cat_train)\n",
    "X_cat_imputed_train = pd.DataFrame(data = X_cat_imputed_train)\n",
    "\n",
    "OE = OneHotEncoder(handle_unknown='ignore')\n",
    "OE.fit(X_cat_imputed_train)\n",
    "X_cat_imputed_train = OE.transform(X_cat_imputed_train)\n",
    "names= OE.get_feature_names()[:]\n",
    "names = names.tolist()\n",
    "X_cat_imputed_train = pd.DataFrame(data = X_cat_imputed_train.toarray(), columns = names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_num_train = X_train.select_dtypes(include='float64')\n",
    "imp_freq_train = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_num_imputed_train = imp_freq_train.fit_transform(X_num_train)\n",
    "X_num_imputed_train = pd.DataFrame(data= X_num_imputed_train, columns = X_num_train.columns)\n",
    "\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_num_imputed_train)\n",
    "X_num_imputed_train = scale.transform(X_num_imputed_train)\n",
    "X_num_imputed_train = pd.DataFrame(data= X_num_imputed_train, columns = X_num_train.columns)\n",
    "\n",
    "\n",
    "X_train_processed = pd.concat([X_cat_imputed_train,X_num_imputed_train],axis =1)\n",
    "\n",
    "y_train =pd.Series(y_train, dtype ='int')\n",
    "///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting K-Means inertia stuff\n",
    "\n",
    "plt.plot([KMeans(n_clusters=i).fit(X).inertia_ for i in range(1,10)])\n",
    "\n",
    "inertia_list = list()\n",
    "img_list = list()\n",
    "for i in range(2,20):\n",
    "    num_clusters = i\n",
    "    im2,km_inertia = image_cluster(img,i)\n",
    "    inertia_list.append(km_inertia)\n",
    "    img_list.append(im2)\n",
    "plt.plot(range(2,20),inertia_list)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('K-means Inertia')\n",
    "\n",
    "def image_cluster(img,k):\n",
    "    ### Write code here\n",
    "    #img = plt.imread(img)\n",
    "    img_flat = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(img_flat)\n",
    "    img_flat2 = img_flat.copy()\n",
    "    # loops for each cluster center\n",
    "    for i in np.unique(kmeans.labels_):\n",
    "        img_flat2[kmeans.labels_==i,:] = kmeans.cluster_centers_[i]\n",
    "    img2 = img_flat2.reshape(img.shape)\n",
    "    plt.imshow(img2)\n",
    "    plt.axis('off');\n",
    "    return img2, kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a decision tree graph:\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=3)\n",
    "clf = clf.fit(X_train_under, y_train_under)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"Fraud\") \n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=features,  \n",
    "                      class_names=['NotFraud','isFraud'], \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve comparison graph\n",
    "\n",
    "\n",
    "def plot_comparison_roc(model_dict, test_x = val_X , test_y = val_Y, ):\n",
    "    \n",
    "    '''\n",
    "    INPUT: dict of trained models, test df\n",
    "    \n",
    "    plots the overlaying roc curves  for comparison purposes.     \n",
    "    '''\n",
    "    \n",
    "    colors = [\n",
    "    'blue',\n",
    "    'green',\n",
    "    'red',\n",
    "    'cyan',\n",
    "    'magenta',\n",
    "    'yellow',\n",
    "    'black',\n",
    "    'violet',\n",
    "    ]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "    \n",
    "    for key, model in model_dict.items():\n",
    "        color = colors[i]\n",
    "        i += 1\n",
    "        i = i % len(colors)\n",
    "        predictions   = model.predict(test_x)  \n",
    "        probabilities = model.predict_proba(test_x)\n",
    "        fpr, tpr, thresholds = roc_curve(test_y, probabilities[:,1])\n",
    "        plt.plot(fpr, tpr, lw = 2, label= key, c = color)\n",
    "        plt.xlim([-0.05,1.05])\n",
    "        plt.ylim([-0.05,1.05])\n",
    "    \n",
    "    plt.plot([0,1],[0,1], c = color, ls='--')\n",
    "    plt.xlabel('False Positive Rate',fontsize = 20)\n",
    "    plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "    plt.title('ROC Curves', fontsize = 20)\n",
    "    plt.legend(loc=\"lower right\", fontsize = 20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpret my Logit coefficients.\n",
    "\n",
    "# Put your beta here\n",
    "beta = 0.5\n",
    "\n",
    "# Don't change this\n",
    "my_list = [i*beta for i in range(0,10)]\n",
    "\n",
    "# Calculating odds\n",
    "odds = [np.exp(i) for i in my_list]\n",
    "\n",
    "# Plotting odds\n",
    "plt.plot(odds)\n",
    "\n",
    "# Interpretation\n",
    "print('For every 1 unit change in my feature, the odds go up by %.2f' % ((odds[1]/odds[0]-1)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
